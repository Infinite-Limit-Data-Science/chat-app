# Inferencial Statistics

### Classical Statistics
There are multiple ways to view probabilities. 

Let's start off with the basics. You may have some observed data. And you may want to learn whether whether the observed sample mean is so far from the hypothesized mean that its mean would be â€œunlikelyâ€ if the hypothesis were true. If itâ€™s â€œtoo far,â€ you reject the hypothesis; otherwise, you fail to reject it. Now maybe the hypothesized mean is correct, and you just happened to get â€œbadâ€ data (an extreme sample). In fact, that can happen, and classical hypothesis testing allows for that possibility. If your sample is unrepresentative (just by random chance or by poor sampling), you could see an extreme sample mean that leads you to reject the hypothesis. Classical hypothesis testing tries to control how often that happens (the Type I error rate) across many repeated experiments.

In classical hypothesis testing (e.g., a zâ€test or tâ€test), the â€œhypothesized meanâ€ is specifically the population mean you assume (under the null hypothesis) before you look at the sample. Youâ€™re effectively saying: $H_0: \mu = \mu_0$ where $\mu_0$ is the hypothesized population mean. Then, using your sample mean $\bar{x}$, you test whether the data are so far from $\mu_0$ as to be â€œunlikelyâ€ under that assumption. The key point is: we usually donâ€™t actually know the true population mean in real-life situations. We only have:
- A claim (e.g., â€œthe manufacturer says the mean battery life is 100 hoursâ€), or
- A theory (e.g., â€œhistorical data suggest the mean is 50â€), or
- Some guess based on partial information.
That hypothesized value $\mu_0$ is what we call the population mean in the null hypothesis. But in practice, it might be the manufacturerâ€™s claim, a researcherâ€™s theory, or some other reference point. We test it against our sample to see if our data conflict with that assumption.

**If you already know the true population mean (i.e., you literally have data for the entire population, or there is some proven fact about that mean), then thereâ€™s no need to run a zâ€test or tâ€test to â€œcheckâ€ it. Why? Because the purpose of these tests is to infer or test a hypothesis about the population mean from a sample. If the population mean is truly known and undisputed, there is no uncertainty to resolve. In other words, hypothesis testing is only necessary when the parameter (like a mean) is unknown and we use sample data to draw conclusions about it.**

We now need to clear up the concept of a population standard deviation. A hypothesized population mean $\mu_0$ is simply the value youâ€™re testing in your null hypothesis: â€œI assume the true mean is 100â€ (for instance), and I want to see if my sample data conflict with that assumption. A population standard deviation Ïƒ is about the spread (variability) in the population. It can come from completely different sourcesâ€”large historical data, industry/engineering specs, or repeated past measurements that have established how much the data typically vary. This means: Even if you arenâ€™t sure the true mean is 100 (thatâ€™s exactly what youâ€™re testing!), you could still have high confidence that the standard deviation is about 10, because many previous studies or manufacturing records have shown the process always has around 10 hours of variability. Hence, in a zâ€test:
- You bring a hypothesized $\mu_0$ (the population mean you want to test).
- You also bring a known ğœ (from historical/industrial knowledge) that describes how wide the distribution is around whatever the true mean is.
They donâ€™t have to come from the same source, and one doesnâ€™t depend on the other. Youâ€™re simply saying, â€œGiven we know the standard deviation is about 10 (from large past data), letâ€™s see if new sample data conflict with the claim that $H_0: \mu = \mu_0$.â€

In classical stats testing, you may have a population mean (hypothesized mean), a population standard deviation and your own sample mean based on sample data. Why do you need a sample mean in z-tests? You need the sample mean in a zâ€test because the whole purpose of the test is to see how far your observed average (from your sample) deviates from the hypothesized population mean $\mu_0$. In other words:
- Null Hypothesis: $H_0: \mu = \mu_0$
    - You propose a value $\mu_0$ for the true mean of the population.
- Observed Sample Mean $\bar{x}$
    - You collect data (a sample) and calculate $\bar{x}$. This is your best estimate of the actual (but unknown) population mean $\mu$.
- Test Statistic z:
    - $z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}$
        - Ïƒ is the known population standard deviation (from external info).
        - ğ‘› is the sample size.
        - The numerator $\bar{x} - \mu_0$ measures how far your sample is from the hypothesized mean.
    - A test statistic ğ‘§ is essentially a standardized measure of how far your observed data (e.g., a sample mean) deviates from the hypothesis or reference value, measured in units of the standard error. 
- Interpretation:
    - If $\bar{x}$ is very far from $\mu_0$ relative to $\sigma / \sqrt{n}$,  then the zâ€value will be large in magnitude, meaning the sample mean is â€œunusually farâ€ from $\mu_0$ (assuming $H_0$ were true). You might then reject $H_0$.
    - If $\bar{x}$ is close to $\mu_0$, the test statistic will be small, suggesting no strong evidence that the true mean differs from $\mu_0$.

How ğ‘§ Relates to the Standard Normal Distribution

A normal distribution is any bell-shaped probability distribution that can be completely described by its mean Î¼ and standard deviation Ïƒ. In mathematical form, if a random variable X is normally distributed, its probability density function is:
$$
f_X(x) = \frac{1}{\sigma \sqrt{2\pi}} 
\, \exp\!\Bigl(-\frac{(x - \mu)^2}{2\sigma^2}\Bigr).
$$
The normal distributionâ€™s probability density function (PDF) can be understood as follows:
- Center at the Mean: The highest point of the curve is at x=Î¼. This reflects that values closest to the mean are the most likely to occur.
- Symmetry Around the Mean: The expression $(x - \mu)^2$ inside the exponential penalizes deviations from the mean equally on both sides. The distribution is symmetric about its mean.
- Spread Controlled by ğœ: The term ğœ (the standard deviation) appears in both the denominator in front and inside the exponent. A larger Ïƒ results in a â€œwiderâ€ curve (since deviations from the mean are less penalized), while a smaller ğœ creates a â€œnarrowerâ€ curve (deviations from the mean become more sharply penalized).
- Exponential Decay: The exponential $\exp\!\Bigl(-\frac{(x - \mu)^2}{2\sigma^2}\Bigr)$ ensures that the probability density decreases very quickly as x moves away from Î¼. Farther values from Î¼ become less probable.
- Normalization by: $\frac{1}{\sigma \sqrt{2\pi}} $: This term ensures that the total area under the curve is 1. 
    - The constant $\sqrt{2\pi}$ appears in many continuous probability distributions.
    - Dividing by Ïƒ scales the curve appropriately so that the integral over all real values of ğ‘¥ equals 1.
These features work together to create the familiar â€œbell shape.â€ Because of the squared term in the exponent, the distribution prioritizes values near Î¼, while making values far from Î¼ increasingly unlikely, providing a smooth, continuous shape that has no sharp edges or discontinuities.

The standard normal distribution is the special case of the normal distribution with mean Î¼=0 and standard deviation Ïƒ=1. Here is why it is so useful and the intuition behind it:
- Simplifies Calculations
    - Any normal distribution can be converted into a standard normal distribution by â€œstandardizingâ€: $Z = \frac{X - \mu}{\sigma}$.
    - This lets us work with a single universal table (or function) for probabilities, rather than having a different table for each Î¼ and ğœ. 
    - A z-table gives values for the cumulative distribution function (CDF) or for tail probabilities for the standard normal distribution.
        - Suppose you have a random variable X (like someoneâ€™s weight in pounds) that follows a normal distribution with mean Î¼=100 and standard deviation  Ïƒ=5. Now imagine we observe a single person whose weight X=105.
        - To convert this specific value into a â€œz-score,â€ we would do: $Z = \frac{X - \mu}{\sigma} = \frac{105 - 100}{5} = 1$
        - So the value 105 is exactly 1 standard deviation above the mean in that particular normal distribution.
        - If you looked up ğ‘=1 in a z-table, youâ€™d see the probability that a standard normal variable is less than or equal to 1 (which is about 0.8413). Translating that back to your specific scenario, it means that roughly 84.13% of people in that population (assuming the model is correct) weigh 105 pounds or less. 
    - In effect, A z-table is basically a lookup chart that tells you the probability that a standard normal variable Z (which has mean 0 and standard deviation 1) will take on a value up to a specific number.  In other words, if you choose a particular z-value (like 1.25), the table tells you the fraction of the area under the bell curve that lies to the left of 1.25. This fraction is the cumulative probability at that z-value.  
- Reference Distribution for â€œZ-Scoresâ€
    - The value ğ‘ tells you how many standard deviations X is away from the mean.
    - This makes Z-scores comparable across different scales. For instance, an observation that is â€œ2 standard deviations above the meanâ€ in one dataset corresponds exactly to Z=2 in the standard normal distribution.
- Foundation for Statistical Inference
    - Many hypothesis tests and confidence intervals (like z-tests) use the standard normal as a reference for deciding how â€œextremeâ€ a sample mean is when scaled by its standard error.
- Intuition: Central Position and Unit Spread
    - Because itâ€™s centered at 0, we measure deviations as positive or negative (above or below the mean).
    - Having a standard deviation of 1 means these deviations are in terms of â€œstandard units,â€ so itâ€™s straightforward to interpret a value like Z=1.96 as being about â€œ1.96 standard deviations above the mean.â€

With regards to the test statistic z in a z-test, once you compute the test statistic ğ‘§, you can think of it as a point on the horizontal axis of this standard normal curve.
    - If ğ‘§=0, it sits at the center (mean = 0)
    - If ğ‘§ is positive, itâ€™s to the right of center; negative ğ‘§ is to the left. The magnitude $\lvert z \rvert$ tells you how many standard deviations away from 0 you are.

Decide on the Significance Level ğ›¼

The choice of ğ›¼ = 0.05 (a 5% significance level) is primarily conventional â€” it arose historically in statistics through the influential work of Ronald A. Fisher and others. Over time, it became a common rule of thumb for distinguishing results that are â€œstatistically significantâ€ from those that are not. 

It helps balancing Type I and Type II errors. A Type I error is rejecting the null hypothesis when it is actually true. ğ›¼ is the maximum risk of committing a Type I error that youâ€™re willing to accept. **At ğ›¼ = 0.05, youâ€™re accepting up to a 5% chance of concluding thereâ€™s an effect (or difference) when in fact there isnâ€™t.**  Is this because the confidence interval is 95 percent and when it falls inside the 95 percent confidence interval we fail to reject the null hypothesis?

Yesâ€”that 5% significance level (ğ›¼ = 0.05) and the 95% confidence interval are directly connected in the usual two-sided test. Hereâ€™s how:
- If the hypothesized value ($\mu_0$, for example)  lies outside the corresponding 95% confidence interval, then you reject $H_0$ at the 5% level.
- If that hypothesized value lies inside the 95% confidence interval, you fail to reject  $H_0$ at the 5% level.
In other words, a 95% confidence interval can be viewed as all the parameter values that would not be rejected by a two-sided test with Î±=0.05. Under the hood, setting Î±=0.05 means you accept up to a 5% chance (in repeated sampling) of rejecting the null hypothesis when it is actually true. A 95% confidence interval means that, in repeated sampling, 95% of those confidence intervals will contain the true parameter. These two perspectives line up so that â€œ95% confidentâ€ corresponds precisely to â€œat most 5% chance of a false positive.â€ 

How to Decide Whether to Reject or Fail to Reject $H_0$

We now have a z-test test statistic. We have a signifance level. The next steps typically go like this to reject or fail to reject the null hypothesis:

Method A: Using a p-value
p-value definition: The p-value is the probability, under the assumption that the null hypothesis ($\mu = \mu_0$) is true, of getting a z-value as extreme or more extreme than the one you got.

Finding the p-value:
- If you do a two-sided test (aka two-tailed test),  (i.e., you care about deviations in either direction), it means weâ€™re checking if the sample mean is either significantly above or significantly below the hypothesized mean. Hence, â€œextremesâ€ lie in both ends (â€œtailsâ€) of the distribution. Hereâ€™s how to see it step by step:



Method B: Using Critical Values

Using a standard normal distribution, you can define a confidence interval built around your sample mean bound by two z-scores defining the curve if it is a two-tail test. You can run a z-test to check if the hypothesized value lies within that interval. If it does, you generally fail to reject the hypothesis at the chosen significance level. This tells you whether your observed data (sample mean) is statistically consistent (not too far off) with the hypothesized mean, given a certain cutoff (e.g. 5% significance). We donâ€™t strictly say â€œaccurateâ€ in the sense of â€œtrue or falseâ€; rather, we say whether or not the difference is statistically significant. This is in essence a z-test or when you don't have the population standard deviation and you have a sample standard deviation, then a t-test, which uses the degree of freedom principle.

z-tests and t-tests don't decide the probability of the hypothesized mean being true or false. Instead, it is a statement about sample data under the assumption that the population mean is correct. Note the hypothesized mean is not the same as the true (unknown) population mean, since knowing the entire population mean is usually impossible.

In contrast to the frequentist tests above (z-tests, t-tests, p-values), in Bayesian inference, given the data, you want to know the probability the hypothesis is true. **Bayesâ€™ theorem is the mathematical engine that flips from â€œthe probability of data given a hypothesisâ€ to â€œthe probability of a hypothesis given the data.â€** In the Bayes formula, you have the Posterior: the probability that the hypothesis is true after seeing the data. In everyday words: â€œNow that I have new information (data), how likely is it that my hypothesis is correct?â€ This is what you want to find out â€“ your updated belief about the hypothesis given the evidence. The Posterior representation: P(Hypothesis âˆ£ Data).

You have the Likelihood value: P(Data âˆ£ Hypothesis). This is the probability of seeing this specific data if the hypothesis were true. In everyday words: â€œHow well does the hypothesis â€˜explainâ€™ or â€˜predictâ€™ the data?â€ Technical detail: This is not the same as the probability of the hypothesis given the data; itâ€™s the other way around.

You have the prior value: P(Hypothesis). Meaning: Your belief about the hypothesis before seeing the new data. In everyday words: â€œHow likely did I think the hypothesis was before I collected any new evidence?â€ Why it matters: In Bayesian thinking, you always start with some prior belief or distribution (even if itâ€™s very broad or â€œuninformativeâ€), because you never come into a problem with zero assumptions. Example: If youâ€™re testing for a rare disease, your prior might be â€œonly 1% of people have it.â€ Or if youâ€™re testing whether a coin is fair, maybe your prior is â€œmost coins are fair,â€ so you start off with a strong prior that the coin has a 50% heads rate.

You have the Evidence (or Marginal Likelihood) value: P(Data). Meaning: The overall probability of observing the data under all possible hypotheses. In everyday words: â€œOut of all the ways I could explain the data, what is the total likelihood of seeing these data at all?â€ Why itâ€™s in the denominator: It acts like a normalizing constant to ensure the result P( Hypothesis âˆ£ Data ) is a proper probability (i.e., sums or integrates to 1 when you consider all possible hypotheses).

$$
\underbrace{P(\text{Hypothesis} \mid \text{Data})}_{\text{Posterior}}
\;=\;
\frac{
  \underbrace{P(\text{Data} \mid \text{Hypothesis})}_{\text{Likelihood}}
  \;\times\;
  \underbrace{P(\text{Hypothesis})}_{\text{Prior}}
}{
  \underbrace{P(\text{Data})}_{\text{Evidence}}
}
$$

Short Example: Disease Testing
- Hypothesis = â€œPerson has the disease.â€
- Prior = Prevalence (say, 1%).
- Likelihood = Probability of a positive test result if the person does have the disease (test sensitivity), and if they donâ€™t (false positive rate).
- Posterior = Probability the person has the disease given that they tested positive.